\documentclass[11pt]{article}

\usepackage[margin=1.0in]{geometry}
\usepackage{url, enumitem}
\usepackage{amsfonts, amsmath, amsthm, amssymb,bbm}
\usepackage{listings}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
 
\urlstyle{same}


\usepackage{color,soul}


\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\theoremstyle{plain}
\usepackage[textsize=tiny]{todonotes}


\usepackage{proof}
\usepackage{bussproofs}

% Some useful macros.
\newcommand{\given}{\,|\,}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}{\text{var}}
\newcommand{\cov}{\text{cov}}
\newcommand{\p}{\partial}
\newcommand{\mba}{\mathbf{a}}
\newcommand{\mbb}{\mathbf{b}}
\newcommand{\mbx}{\mathbf{x}}
\newcommand{\mcX}{\mathcal{X}}
\newcommand{\mcY}{\mathcal{Y}}
\newcommand{\boldw}{\mathbf{w}}
\newcommand{\mbxt}{\tilde{\mathbf{x}}}
\newcommand{\Sigmat}{\tilde{\Sigma}}
\newcommand{\mbz}{\mathbf{z}}
\newcommand{\mbw}{\mathbf{w}}
\newcommand{\mcN}{\mathcal{N}}
\newcommand{\mcP}{\mathcal{P}}
\newcommand{\eps}{\epsilon}
\newcommand{\trans}{\intercal}
\newcommand{\Ut}{\tilde{U}}
\newcommand{\Beta}{\text{Beta}}
\newcommand{\Bernoulli}{\text{Bernoulli}}
\newcommand{\Elbo}{\text{ELBO}}
\newcommand{\KL}{\text{KL}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\angstrom}{\textup{\AA}}
\renewcommand{\v}[1]{\mathbf{#1}}
\renewcommand{\b}[1]{\mathbb{#1}}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta
    urlcolor=cyan,
}
\lstset{
    basicstyle=\ttfamily,
    mathescape
}


% Author: Mark Goldstein
% Date: Summer 2018
\begin{document}
\begin{center}
Semantics of Probabilistic Programs\\
Mark Goldstein
\end{center}

\section{Intro}

\noindent A walkthrough of [1] and [2], mainly focusing on the presentation 
in [2]. We first briefly review measures and kernels because
they show up in the semantics.

\section{Measure Theory}

\noindent A $\mathbf{\sigma}$-\textbf{algebra} $\Sigma_X$ on a set $X$ is a collection
of subsets of $X$ that contains $\emptyset$ and is closed under complements
and countable unions. A \textbf{measurable space} is a pair $(X,\Sigma_X)$ of
a set and a $\sigma$-algebra on it. The elements of $\Sigma_X$, which are themselves
sets of elements in $X$, are called \textbf{measurable sets}.
For example, the Borel sets are the smallest $\sigma$-algebra on $\b{R}$ that
contains the intervals. This is the usual $\sigma$-algebra for $\b{R}$. For any countable
set, you can always start off with the individual elements of the set: satisfying
complements and unions this gives you the powerset $\sigma$-algebra.\\

\noindent A \textbf{measure} on a measurable space $(X,\Sigma_X)$ is a function
$\mu: \Sigma_X \rightarrow [0,\infty]$ into the set $[0,\infty]$ of extended
non-negative reals that takes countable disjoint unions to sums, i.e. $\mu(\emptyset)=0$
and $\mu(\cup_{n \in \b{N}} U_n) = \Sigma_{n \in \b{N}} \mu(U_n)$ 
for any $\b{N}$-indexed sequence of disjoint measurable sets $U_n$.
A \textbf{probability measure} is a measure $\mu$ such that $\mu(X)=1$.
For example, the Lebesgue measure $\lambda$ on $\b{R}$ is generated by
$\lambda \Big( (a,b) \Big) = b-a$. For any $x \in X$, the Dirac measure 
$\delta_x(U) = 1$ if $x \in U$ and $0$ otherwise.\\

\noindent A \textbf{kernel} $k$ from $X$ to $Y$, notated
$k: X \rightsquigarrow Y$, is a function $k: X \times \Sigma_Y \rightarrow [0,\infty]$
such that

\begin{itemize}
    \item for fixed $x$, $k(x,-): \Sigma_Y \rightarrow [0,\infty]$ is a measure
    \item for fixed $dy$, $k(-,dy): X \rightarrow [0,\infty]$ is a measurable function.
\end{itemize}

\noindent An intuitive example of kernels at work is conditional probability.
Take $k(x,-)$ to be a probability measure $\mu_Y: \Sigma_Y \rightarrow [0,1]$ on $Y$ given a particular value $X=x$:
$\sum_{dy \in \Sigma_y} k(x,dy) = 1$. Note that $\sum_{x \in X} k(x,dy) \neq 1$ in general.\\

%\noindent Let $X,Y,Z$ be measurable spaces and let
%$k^1 : X \times Y \rightsquigarrow Z$ and 
%$k^2 : X \rightsquigarrow Y$ be s-finite kernels (\textbf{TODO}: explain s-finiteness). 
%Then we can define the composition $(k^1 \star k^2) : X \rightsquigarrow Z$ as

%$$ (k^1 \star k^2)(x,U) = \int_Y k^2(x,dy) k^1(x,y,U) $$

%\noindent For intuition, consider $k(x,-): \Sigma_Y \rightarrow [0,1]$
%to be the probability measure that tells you how likely it is to start
%off at location $x$ and end up in the interval $dy$. 

%Then the composition $(k^1 \star k^2)(x,dz) = \int_Y k^2(x,dy) k^1(x,y,dz)$ can be taken to represent
%the probability of starting off at $x$ and ending up in the interval $dz$, where
%we take a step in-between to land on $y$, but average out across all intervals
%$dy$ that we can land in when jumping from $x$.\\

\section{Types and Semantics}

\noindent The two papers [1,2] don't actually define the set of terms,
but they are implied to be the typical ones in a language like Haskell.
The 2018 POPL paper on semantics for higher-order languages [3] does formally
introduce a kind and type system and a set of terms. We define our types as:

$$ \b{A},\b{B} ::= 
    \b{R} | P(\b{A}) | 1 | \b{A} \times \b{B} | \sum_i \b{A}_{i \in I} $$

\noindent where $I$ is countable and non-empty. As we will see, 
types are to be interpreted as measurable spaces $[[\b{A}]]$. 
We have sum and product types. We have a type $\b{R}$ that denotes the Reals $[[\b{R}]]$. 
We have a type $P(\b{A})$ that denotes the set of probability measures $[[P(\b{A})]]$
over a space denoted by $\b{A}$. We have the type $1$ the denotes a singleton set. 
For bools, we can just take $(1+1)$ and $P(1+1)$ is the type for distributions over bools.
For the natural numbers, we can use $\sum_{i \in \b{N}} 1$. \\

\noindent \textbf{Typing judgements:} $\Gamma \vdash_d$ for deterministic
judgements and $\Gamma \vdash_p$ for probabilistic judgements. Having the two
typing judgements is mainly for notational clarity: it helps us to define 
interpretation differently for deterministic and probabilistic terms. \\


\subsection{Typing Judgements and Interpretations for Deterministic Terms}

\noindent Deterministic terms  $\Gamma \vdash_d t : \b{A}$ are interpreted
as measurable functions $[[t]]: [[\Gamma]] \rightarrow [[\b{A}]]$,
where $[[t]](\gamma) = x$ is an element of the underlying set
$[[\b{A}]]$ and not a measurable set in $\Sigma_{[[\b{A}]]}$.
\textbf{Note:} the following informally uses the notation 
$\Gamma::(x:\b{A})::\Gamma^\prime$ to show a particular variable $x$
of type $\b{A}$ in the environment.

\begin{itemize}


    \item \textbf{basic term} $x:\b{A}$
        
         \begin{center}
            \AxiomC{}
            \RightLabel{\quad \quad \quad $[[x]](\gamma::d::\gamma^\prime) = d$}
            \UnaryInfC{$\Gamma::(x:A)::\Gamma^\prime \vdash_d x: \b{A}$}
            \DisplayProof
         \end{center}

    \item \textbf{Disjoint Sum Type}

        \begin{center}
            \AxiomC{$\Gamma \vdash_d t: \b{A}_i$}
            \RightLabel{\quad \quad \quad $[[(i,t)]](\gamma) = (i,[[t]](\gamma))$}
            \UnaryInfC{$\Gamma \vdash_d (i,t): \sum_{i \in I} \b{A}_i$}
            \DisplayProof
        \end{center}

    \item \textbf{Deterministic \texttt{case}}

        \begin{center}
            \AxiomC{$\Gamma \vdash_d t : \sum_{i \in I} \b{A}_i$}
            \AxiomC{$(\Gamma::(x:\b{A}_i) \vdash_d u_i : \b{B})_{i \in I}$}
            \BinaryInfC{$\Gamma \vdash_d (\texttt{case } t \texttt{ of }
                \{(i,x) \rightarrow u_i \}_{i \in I}): \v{B}$} 
            \DisplayProof
        \end{center}
        $$[[\texttt{case } t \texttt{ of } \{(i,x) 
            \rightarrow u_i\}_{i \in I}]](\gamma) = 
            [[u_i]](\gamma,d) \texttt{ if } [[t]](\gamma) = (i,d)$$

    \item \textbf{Unit ()}

        \begin{center}
            \AxiomC{}
            \RightLabel{\quad \quad \quad $[[()]](\gamma) = ()$}
            \UnaryInfC{$\Gamma \vdash_d (): 1$}
            \DisplayProof
        \end{center}
  
    \item \textbf{Product Type}
        \begin{center}
            \AxiomC{$\Gamma \vdash_d t_0:\b{A}_0$}
            \AxiomC{$\Gamma \vdash_d t_1:\b{A}_1$}
            \RightLabel{\quad \quad \quad 
                $[[(t_0,t_1)]](\gamma) = ([[t_0]](\gamma),[[t_1]](\gamma))$}
            \BinaryInfC{$\Gamma \vdash_d (t_0,t_1): \b{A}_0 \times \b{A}_1$}
            \DisplayProof
        \end{center}
    
    \item \textbf{Projection}
        \begin{center}
            \AxiomC{$\Gamma \vdash_d t: \b{A}_0 \times \b{A}_1$}
            \RightLabel{\quad \quad \quad 
                $[[\pi_j(t)]](\gamma) = d_j$ if $[[t]](\gamma) = (d_0,d_1)$}
            \UnaryInfC{$\Gamma \vdash_d \pi_j(t):\b{A}_j$}
            \DisplayProof
        \end{center}
\end{itemize}

\noindent where the $\texttt{case}$ expression above has a
deterministic continuation $u_i$. We will come back to the 
probabilistic continuation case. Now the semantics for sequencing.

\subsection{Typing Judgements and Interpretations for Probabilistic Terms}

\noindent Probabilistic terms $\Gamma \vdash_p t : \b{A}$ are interpreted
as s-finite kernels $[[t]]: [[\Gamma]] \rightsquigarrow [[\b{A}]]$.

\begin{itemize}

\item \noindent \textbf{\texttt{return}(t)}

\begin{center}
    \AxiomC{$\Gamma \vdash_d t : \b{A}$}
    \RightLabel{\quad \quad \quad $[[\texttt{return}(t)]](\gamma,da) =
      \delta_{[[t]](\gamma)}(da)$}
    \UnaryInfC{$ \Gamma \vdash_p \texttt{return}(t): \b{A}$}
    \DisplayProof
\end{center}


\noindent this corresponds to a Dirac Delta measure sitting at
a point $[[t]](\gamma)$. \\

\item \noindent \textbf{\texttt{let} x = t \texttt{ in } u}


%\begin{center}
%    \AxiomC{$\Gamma \vdash_p t : \b{A} \quad \Gamma,x:\b{A} \vdash_p u : \b{B}$}
%    \RightLabel{\quad \quad \quad 
%                $[[\texttt{let } x = t \texttt{ in } u]](\gamma,db) =
%          \displaystyle{\int}_{x,dx \in [[\b{A}]]} 
%                      [[u]] \Big( \gamma,x,db \Big) [[t]]\Big( \gamma,dx \Big)$}
%    \UnaryInfC{$\Gamma \vdash_p \texttt{let } x=t \texttt{ in } u : \b{B}$}
%    \DisplayProof
%\end{center}
%
%\noindent This one takes careful reading. Consider the kernel
%composition definition above. Take $k_1$ to be $[[u]]$ and take
%$k_2$ to be $[[t]]$. Then $(k^1 \star k^2)(\gamma, db) 
%= ([[u]] \star [[t]])(\gamma, db)$\\

\begin{center}
    \AxiomC{$\Gamma \vdash_p t : \b{A} \quad \Gamma,x:\b{A} \vdash_p u : \b{B}$}
    \RightLabel{\quad \quad \quad 
                $[[\texttt{let } x = t \texttt{ in } u]](\gamma,db) =
          \displaystyle{\int}_{x,dx \in [[\b{A}]]} 
                      [[u]] \Big(\gamma::x,db \Big) [[t]]\Big(\gamma,dx \Big)$}
    \UnaryInfC{$\Gamma \vdash_p \texttt{let } x=t \texttt{ in } u : \b{B}$}
    \DisplayProof
\end{center}

\item \noindent \textbf{probabilistic \texttt{case}}

\begin{center}
  \AxiomC{$\Gamma \vdash_d t : \sum_{i \in I} \b{A}_i$}
  \AxiomC{$(\Gamma,x:\b{A}_i \vdash_p u_i : \b{B})_{i \in I}$}
  \BinaryInfC{$\Gamma \vdash_p (\texttt{case } t \texttt{ of }
              \{(i,x) \rightarrow u_i \}_{i \in I}): \b{B}$} 
  \DisplayProof
\end{center}

$$ [[\texttt{case } t \texttt{ of } \{(i,x) \rightarrow u_i \}_{i \in I} ]]
    (\gamma,db) = [[u_i]](\gamma::d,db) \texttt { if } [[t]](\gamma) =(i,d)$$

\item \noindent \textbf{\texttt{sample}(t)}

\begin{center}
    \AxiomC{$\Gamma \vdash_d t : P(\b{A})$}
    \RightLabel{\quad \quad \quad 
      $[[\texttt{sample}(t)]](\gamma,da) = 
      \Big([[t]](\gamma)\Big)(da)$}
    \UnaryInfC{$ \Gamma \vdash_p \texttt{sample}(t): \b{A}$}
    \DisplayProof
\end{center} 

\item \noindent \textbf{\texttt{score}(t)}

\begin{center}
    \AxiomC{$ \Gamma \vdash_d t : \b{R}$}
    \UnaryInfC{$\Gamma \vdash_p \texttt{score}(t): 1$}
    \DisplayProof
\end{center}

\[ 
  [[\texttt{score}(t)]](\gamma,du) = 
    \left\{\begin{array}{lr}
     abs \Big( [[t]](\gamma) \Big), & \text{if } du=\{()\}\\
     0, & \text{if } du=\emptyset 
    \end{array}\right\}
\]

\end{itemize}

\subsection{Typing Judgements and Interpretation for Normalize}

\noindent \textbf{TODO}

%\begin{center}
%    \AxiomC{$\Gamma \vdash_p t : \b{A}$}
%    \UnaryInfC{$\Gamma \vdash_d \texttt{normalize}(t): \b{R} \times P(\b{A}) + 1 + 1$}
%    \DisplayProof
%\end{center}
%
%\noindent To give it a semantics, we must find the normalizing constant to 
%divide by. Consider $\Gamma \vdash_p t : \b{A}$ and 
%let $\texttt{evidence}_t = [[t]]_{\gamma,[[\b{A}]]}$. Then:
%
%\[ 
%  [[\texttt{normalize}(t)]](\gamma) = 
%    \left\{\begin{array}{lr}
%    (0,(\texttt{evidence}_t, \frac{[[t]](\gamma,(-))}{\texttt{evidence}_t})), &
%            \text{if } \texttt{evidence}_t \in (0,\infty)\\
%    (1,()), & \text{if } \texttt{evidence}_t = 0\\
%    (2,()), & \text{if } \texttt{evidence}_t = \infty
%    \end{array}\right\}
%\]

\newpage

\section{Example Programs}


\noindent Beta-Bernoulli model: in the following, we derive that ``the un-normalized posterior is a measure defined by integrating the likelihood with respect to the prior".

    $$[[\texttt{let } x = \texttt{sample}(\texttt{Beta}(2,2)) \texttt{ in score} (\texttt{Bernoulli}(1;x));\texttt{return}(x)]](db)$$

\begin{align*}
    &= \int_x \quad [[\texttt{let } a =\texttt{score}(\texttt{Bernoulli}(1;x)) \texttt{ in return}(x)]](\gamma::x, db) 
        \quad [[\texttt{sample}(\texttt{Beta}(2,2))]](\gamma,dx)\\
    &= \int_x \quad [[\texttt{let } a =\texttt{score}(\texttt{Bernoulli}(1;x)) \texttt{ in return}(x)]](\gamma::x, db) 
        \quad \texttt{Beta}(dx;2,2)\\
    &= \int_x 
        \Big( \sum_{s \in \{\emptyset,\{()\} \}} [[\texttt{return}(x)]](\gamma::x::a,db) \quad [[\texttt{score}(\texttt{Bernoulli}(1;x))]](\gamma::x,s) \Big)
        \quad \texttt{Beta}(dx;2,2)\\
    &= \int_x 
        \Big( [[\texttt{return}(x)]](\gamma::x::a,db) \quad [[\texttt{score}(\texttt{Bernoulli}(1;x))]](\gamma::x,\{()\}) \Big)
        \quad \texttt{Beta}(dx;2,2)\\
    &= \int_x 
        \Big( [[\texttt{return}(x)]](\gamma::x::a,db) \quad \texttt{Bernoulli}(1;x) \Big)
        \quad \texttt{Beta}(dx;2,2)\\
    &= \int_x 
        \Big(\mathbbm{1}\big[ x \in db \big] \quad \texttt{Bernoulli}(1;x) \Big)
        \quad \texttt{Beta}(dx;2,2)\\
    &= \texttt{UnnormalizedPosterior}(db) = \int_{x \in db} 
        \texttt{Bernoulli}(1;x) \quad \texttt{Beta}(dx;2,2)\\
        &= \int_{x \in db} \Big(x^{2 + 1 - 1}(1-x)^{2 - 1}\Big)
    \end{align*}

\noindent This gives the expected result. We were able to interpret the program as an un-normalized posterior for a Beta-Bernoulli model.\\

\noindent Note on conjugacy: In this example, we consider a Beta-Bernoulli model. 
The Beta distribution is a continuous distribution over $[0,1]$ whose shape is determined by two parameters $\alpha$ and $\beta$ so that the density is 
$\Beta(x;\alpha,\beta) = \frac{1}{C(\alpha,\beta)}x^{\alpha-1} (1-x)^{\beta=1}$ where $C(\alpha,\beta)$ is just a normalizing constant. 
The Bernoulli distribution is a discrete distribution over $\{0,1\}$ with parameter $x \in [0,1]$
defined by mass function $\texttt{Bernoulli}(d;x) = x$ if $d=1$ and $1-x$ if $d=0$. The two distributions have the following property:
if $x$ is distributed $\texttt{Beta}(\alpha,\beta)$ and you observe data-points $d_i \in \{0,1\}$ with likelihood distribution
$\prod_i \texttt{Bernoulli}(d_i;x)$ (Bernoulli with parameter $x$), then the posterior distribution over $x$ is $\texttt{Beta}(\alpha + \#1,\beta + \#0)$, where
there are $\#1$ $1's$ and $\#0$ $0's$ in the data. This is a result coming from the Beta and Bernoulli being a \textbf{conjugate pair}. If we were to wrap
the entire program in a call to $\texttt{normalize()}$, we should get a measure with density $\texttt{Beta}(2 + 1, 2)$\\

\noindent \textbf{TODO}: Definition of Density: if $f(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{1}{2}x^2}$,
then: ...\\

%\begin{align*}
%    &[[ \vdash_p \texttt{let } x = \texttt{ sample}(gauss(0,1)) \texttt{ in score}
%        (1/f(x));\texttt{ return}(x): \b{R}]](U)\\
%    &=\\
%    &lebesgue(U)
%\end{align*}

\noindent \textbf{TODO}: For probability measure $p$ with density $g$, recover the importance
sampling algorithm for sampling from $p$ by sampling from a Gaussian by showing:
\begin{align*}
    [[\texttt{sample}(p)]] &= [[\texttt{let } x = lebesgue
           \texttt{ in score}(p(x)); \texttt {return}(x) ]]\\
                    &= [[\texttt{let } x = gauss(0,1) \texttt{ in score}
                (1/f(x)); \texttt{score}(g(x));\texttt{return}(x)]]\\
                &= [[\texttt{let } x = gauss(0,1) \texttt{ in score}
                (g(x)/f(x)); \texttt{return}(x)]]
\end{align*}




\section{Higher Order}

\noindent ...

\section{Citation}

\begin{enumerate}
  \item Staton et al. Semantics for probabilistic programming: higher-order
        functions, continuous distributions, and soft constraints. LICS 2016.
        \url{https://arxiv.org/pdf/1601.04943.pdf}

  \item Staton. Commutative semantics for probabilistic programming. ESOP 2017.
`        \url{http://www.cs.ox.ac.uk/people/samuel.staton/papers/esop2017.pdf}

  \item Scibior et al. Denotational validation of Bayesian inference. POPL 2018.
        \url{https://arxiv.org/pdf/1711.03219.pdf}

\end{enumerate}

% \infer{B}{A & (A \rightarrow B)}  


\end{document}



